# 25 . **Working with Data in Python**

Data manipulation is one of the most common tasks in programming, especially when dealing with large datasets. Python provides powerful libraries like **NumPy** and **Pandas** for handling and analyzing data efficiently. Additionally, Python has built-in support for reading and writing data in various file formats, such as **CSV**, **JSON**, and **Excel**.

Let's break down the basics of **NumPy**, **Pandas**, and working with different file formats.

---

## **1. NumPy Basics**

**NumPy** is a fundamental library for numerical computing in Python. It provides support for arrays, matrices, and many mathematical functions to operate on these arrays.

### **Creating Arrays with NumPy**

To start working with NumPy, you need to import the `numpy` module.

```python
import numpy as np

# Creating a 1D array (vector)
arr1 = np.array([1, 2, 3, 4, 5])
print(arr1)  # Output: [1 2 3 4 5]

# Creating a 2D array (matrix)
arr2 = np.array([[1, 2, 3], [4, 5, 6]])
print(arr2)
# Output:
# [[1 2 3]
#  [4 5 6]]
```

### **Array Operations**

NumPy arrays support element-wise operations, making it easier to perform mathematical computations.

```python
arr = np.array([1, 2, 3])

# Element-wise addition
arr2 = arr + 2
print(arr2)  # Output: [3 4 5]

# Element-wise multiplication
arr3 = arr * 3
print(arr3)  # Output: [3 6 9]
```

### **Array Reshaping and Slicing**

You can reshape arrays to different dimensions and slice them just like lists.

```python
# Reshape a 1D array to a 2D array
arr = np.array([1, 2, 3, 4, 5, 6])
reshaped_arr = arr.reshape(2, 3)
print(reshaped_arr)
# Output:
# [[1 2 3]
#  [4 5 6]]

# Slicing a NumPy array
arr = np.array([10, 20, 30, 40, 50])
slice_arr = arr[1:4]
print(slice_arr)  # Output: [20 30 40]
```

## **Common NumPy Functions**

```python
# Generate an array of zeros
zeros_arr = np.zeros(5)
print(zeros_arr)  # Output: [0. 0. 0. 0. 0.]

# Generate an array of ones
ones_arr = np.ones(3)
print(ones_arr)  # Output: [1. 1. 1.]

# Generate a range of values
range_arr = np.arange(0, 10, 2)
print(range_arr)  # Output: [0 2 4 6 8]

# Calculate the mean and standard deviation
mean = np.mean(arr)
std = np.std(arr)
print(f"Mean: {mean}, Std: {std}")
```

---

## **2. Pandas Basics**

**Pandas** is a high-level library built on top of NumPy for data manipulation and analysis. The primary data structures in Pandas are **Series** and **DataFrame**.

### **Creating a Pandas Series**

A **Series** is a one-dimensional labeled array, similar to a column in a spreadsheet.

```python
import pandas as pd

# Creating a Pandas Series
s = pd.Series([1, 2, 3, 4, 5])
print(s)
# Output:
# 0    1
# 1    2
# 2    3
# 3    4
# 4    5
# dtype: int64
```

### **Creating a Pandas DataFrame**

A **DataFrame** is a two-dimensional, size-mutable, and potentially heterogeneous tabular data structure with labeled axes (rows and columns).

```python
# Creating a DataFrame
data = {'Name': ['Alice', 'Bob', 'Charlie'],
        'Age': [25, 30, 35],
        'City': ['New York', 'Los Angeles', 'Chicago']}
df = pd.DataFrame(data)
print(df)
# Output:
#       Name  Age         City
# 0    Alice   25     New York
# 1      Bob   30  Los Angeles
# 2  Charlie   35      Chicago
```

### **DataFrame Operations**

You can access columns, rows, and perform various operations like filtering, sorting, and aggregation.

```python
# Accessing columns
print(df['Name'])  # Output: Series with Name column

# Filtering rows based on a condition
filtered_df = df[df['Age'] > 30]
print(filtered_df)
# Output:
#       Name  Age     City
# 2  Charlie   35  Chicago

# Sorting by a column
sorted_df = df.sort_values(by='Age')
print(sorted_df)
```

### **Basic DataFrame Methods**

* **`head()`**: Returns the first few rows of the DataFrame.
* **`describe()`**: Returns descriptive statistics of the DataFrame.
* **`info()`**: Provides a summary of the DataFrame.

```python
print(df.head(2))  # Output: First 2 rows of the DataFrame
print(df.describe())  # Output: Descriptive statistics (e.g., mean, std)
print(df.info())  # Output: Information about DataFrame columns and types
```

---

## **3. Working with File Formats**

Python supports various file formats for reading and writing data. The most common formats are **CSV**, **JSON**, and **Excel**.

### **CSV Files**

CSV (Comma Separated Values) is a popular format for storing tabular data. You can easily read and write CSV files using **Pandas**.

### **Reading CSV Files**

```python
import pandas as pd

# Reading a CSV file
df = pd.read_csv('data.csv')
print(df)
```

### **Writing to CSV Files**

```python
# Writing to a CSV file
df.to_csv('output.csv', index=False)
```

### **JSON Files**

JSON (JavaScript Object Notation) is a lightweight data-interchange format that is easy for humans to read and write. Pandas makes it easy to work with JSON files.

### **Reading JSON Files**

```python
# Reading a JSON file
df = pd.read_json('data.json')
print(df)
```

### **Writing to JSON Files**

```python
# Writing to a JSON file
df.to_json('output.json')
```

### **Excel Files**

Pandas also supports reading from and writing to Excel files, which is useful for handling spreadsheets.

### **Reading Excel Files**

```python
# Reading an Excel file
df = pd.read_excel('data.xlsx')
print(df)
```

### **Writing to Excel Files**

```python
# Writing to an Excel file
df.to_excel('output.xlsx', index=False)
```

## **File Path Operations**

Python also provides modules like **`os`** and **`pathlib`** for working with file paths.

```python
import os

# Get the current working directory
print(os.getcwd())

# Join paths
file_path = os.path.join("folder", "file.csv")
print(file_path)
```

---

## **4. Best Practices for Working with Data**

* **Data Cleaning**: Before analyzing data, ensure that it’s clean. Handle missing data, remove duplicates, and address inconsistencies.
* **Efficiency**: Use Pandas for large datasets as it is optimized for speed and memory efficiency. Use **NumPy** for numerical computations.
* **Data Validation**: Ensure that the data conforms to expected formats and values before using it in models or analyses.
* **Visualization**: Use **Matplotlib** or **Seaborn** to visualize your data before analysis. This helps identify patterns and outliers.

---

### **Why Use NumPy and Pandas?**

* **NumPy** is essential for numerical computing and handling arrays and matrices efficiently. It’s the foundation for most scientific and analytical Python libraries.
* **Pandas** is great for data manipulation, cleaning, and analysis. It simplifies tasks like filtering, grouping, and merging data, which are common in data science.
* **File Format Handling** allows you to seamlessly read and write various data formats, enabling integration with other systems and tools.

Mastering **NumPy** and **Pandas** is essential for data science, machine learning, and general data analysis, enabling you to manipulate and analyze large datasets with ease.
